name: run-analysis

on:
  workflow_dispatch:

jobs:
  run-figures:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install .[test]
          pip install seaborn matplotlib adjustText requests

      - name: Download analysis artefacts
        shell: bash
        run: |
          set -euo pipefail

          base='https://sharedspace.s3.msi.umn.edu'

          mapfile -t URLS <<'EOF'
          https://sharedspace.s3.msi.umn.edu/public_internet/paml_results.checkpoint.tsv
          https://sharedspace.s3.msi.umn.edu/public_internet/inversion_fst_estimates.tsv
          https://sharedspace.s3.msi.umn.edu/public_internet/inv_info.csv
          EOF

          mkdir -p analysis_downloads
          : > analysis_downloads/.downloaded_files

          for url in "${URLS[@]}"; do
            rel="${url#${base}/}"
            out="analysis_downloads/${rel}"
            mkdir -p "$(dirname "$out")"
            echo "Fetching $url"
            if ! curl -fSL --retry 3 "$url" -o "$out"; then
              echo "Warning: failed to fetch $url; continuing"
              rm -f "$out"
              continue
            fi
            echo "$out" >> analysis_downloads/.downloaded_files
          done

          while IFS= read -r f; do
            echo "===== HEAD: $f ====="
            head -n 10 "$f" || true
            echo
          done < analysis_downloads/.downloaded_files

      - name: Download manual VCF workflow artefacts
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail

          python - <<'PY'
          import io
          import os
          import zipfile
          from pathlib import Path

          import requests

          repo = os.environ.get("GITHUB_REPOSITORY")
          token = os.environ.get("GITHUB_TOKEN")
          if not repo:
              raise SystemExit("GITHUB_REPOSITORY environment variable is required")
          if not token:
              raise SystemExit("GITHUB_TOKEN environment variable is required to download artefacts")

          workflow_file = "manual_run_vcf.yml"
          session = requests.Session()
          session.headers.update(
              {
                  "Authorization": f"Bearer {token}",
                  "Accept": "application/vnd.github+json",
                  "X-GitHub-Api-Version": "2022-11-28",
              }
          )

          def api_get(url: str, **params):
              response = session.get(url, params=params)
              response.raise_for_status()
              return response

          runs_url = f"https://api.github.com/repos/{repo}/actions/workflows/{workflow_file}/runs"
          runs = api_get(runs_url, status="success", exclude_pull_requests="true", per_page=1).json().get("workflow_runs", [])
          if not runs:
              raise SystemExit("No successful runs found for manual_run_vcf.yml")

          run = runs[0]
          run_id = run["id"]
          print(f"Using manual_run_vcf.yml artefacts from run {run_id} ({run['html_url']})")

          artifacts_url = f"https://api.github.com/repos/{repo}/actions/runs/{run_id}/artifacts"
          artifacts = {
              artifact["name"]: artifact
              for artifact in api_get(artifacts_url, per_page=100).json().get("artifacts", [])
          }

          required = {
              "run-vcf-output-csv": "output.csv",
              "run-vcf-falsta": None,
              "run-vcf-hudson-fst": "hudson_fst_results.tsv.gz",
          }

          missing = [name for name in required if name not in artifacts]
          if missing:
              raise SystemExit(f"Missing required artefacts from manual_run_vcf.yml: {', '.join(missing)}")

          repo_root = Path(".").resolve()
          downloads_root = repo_root / "analysis_downloads"
          public_root = downloads_root / "public_internet"
          public_root.mkdir(parents=True, exist_ok=True)
          download_log = downloads_root / ".downloaded_files"
          download_log.parent.mkdir(parents=True, exist_ok=True)
          if not download_log.exists():
              download_log.touch()

          def download_artifact(artifact):
              url = artifact["archive_download_url"]
              print(f"Downloading artefact: {artifact['name']}")
              resp = session.get(url)
              resp.raise_for_status()
              return zipfile.ZipFile(io.BytesIO(resp.content))

          log_entries = []
          # output.csv
          with download_artifact(artifacts["run-vcf-output-csv"]) as zf:
              for member in zf.namelist():
                  if member.endswith("output.csv"):
                      target = public_root / "output.csv"
                      target.parent.mkdir(parents=True, exist_ok=True)
                      with target.open("wb") as fh:
                          fh.write(zf.read(member))
                      log_entries.append(target)
                      print(f"Wrote {target.relative_to(repo_root)}")
                      break
              else:
                  raise SystemExit("output.csv not found in run-vcf-output-csv artefact")

          # FALSTA files
          with download_artifact(artifacts["run-vcf-falsta"]) as zf:
              extracted = False
              for member in zf.namelist():
                  if member.endswith(".falsta") or member.endswith(".falsta.gz"):
                      target = public_root / Path(member).name
                      target.parent.mkdir(parents=True, exist_ok=True)
                      with target.open("wb") as fh:
                          fh.write(zf.read(member))
                      log_entries.append(target)
                      print(f"Wrote {target.relative_to(repo_root)}")
                      extracted = True
              if not extracted:
                  raise SystemExit("No .falsta or .falsta.gz files found in run-vcf-falsta artefact")

          # Hudson FST results
          with download_artifact(artifacts["run-vcf-hudson-fst"]) as zf:
              for member in zf.namelist():
                  if member.endswith("hudson_fst_results.tsv") or member.endswith("hudson_fst_results.tsv.gz"):
                      target_name = Path(member).name
                      target = public_root / target_name
                      target.parent.mkdir(parents=True, exist_ok=True)
                      with target.open("wb") as fh:
                          fh.write(zf.read(member))
                      log_entries.append(target)
                      print(f"Wrote {target.relative_to(repo_root)}")
                      break
              else:
                  raise SystemExit("hudson_fst_results.tsv(.gz) not found in run-vcf-hudson-fst artefact")

          with download_log.open("a", encoding="utf-8") as fh:
              for path in log_entries:
                  try:
                      fh.write(str(path.relative_to(repo_root)) + "\n")
                  except ValueError:
                      fh.write(str(path) + "\n")
          PY

      - name: Run replicate_figures.py
        id: run-figures
        shell: bash
        run: |
          status=0
          python scripts/replicate_figures.py --skip-downloads || status=$?
          echo "replicate_figures_exit_code=$status" >> "$GITHUB_OUTPUT"
          if [[ $status -ne 0 ]]; then
            echo "replicate_figures.py exited with status $status but continuing to allow artifact upload."
          fi

      - name: Post-run diagnostics
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          echo '=== Repository root contents ==='
          ls -al
          echo '=== Generated figures (top level) ==='
          find . -maxdepth 1 -type f \( -name '*.png' -o -name '*.pdf' -o -name '*.svg' \) -print
          echo '=== Generated figures (within subdirectories) ==='
          find stats -maxdepth 3 -type f \( -name '*.png' -o -name '*.pdf' -o -name '*.svg' \) -print || true
          echo '=== Download directory structure ==='
          find analysis_downloads -maxdepth 2 -type f -print
          echo '=== Disk usage summary ==='
          du -h --max-depth=1

      - name: Collect generated outputs
        if: always()
        run: |
          python - <<'PY'
          import shutil
          from pathlib import Path

          root = Path('.')
          figures_dest = Path('artifacts/figures')
          figures_dest.mkdir(parents=True, exist_ok=True)
          skip_dirs = {'analysis_downloads', 'artifacts'}
          for pattern in ('*.png', '*.pdf', '*.svg', '*.txt', '*.tsv', '*.csv'):
              for path in root.rglob(pattern):
                  if path.is_file():
                      if any(part in skip_dirs for part in path.parts):
                          continue
                      rel = path.relative_to(root)
                      target = figures_dest / rel
                      target.parent.mkdir(parents=True, exist_ok=True)
                      shutil.copy2(path, target)

          downloads_src = Path('analysis_downloads')
          downloads_dest = Path('artifacts/downloads')
          if downloads_src.exists():
              if downloads_dest.exists():
                  shutil.rmtree(downloads_dest)
              shutil.copytree(downloads_src, downloads_dest)
          PY

      - name: Upload figure artefacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: figure-outputs
          path: artifacts/figures
          if-no-files-found: warn

      - name: Upload downloaded data artefacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-downloads
          path: artifacts/downloads
          if-no-files-found: warn

